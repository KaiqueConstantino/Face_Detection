{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognition Project\n",
    "\n",
    "##### PT:\n",
    "Importação das bibliotecas necessárias para o projeto.\n",
    "TensorFlow será usado para construir e treinar o modelo de aprendizado profundo.\n",
    "MobileNetV2 é um modelo pré-treinado utilizado para Transfer Learning.\n",
    "ImageDataGenerator é usado para pré-processar e aumentar os dados de entrada.\n",
    "\n",
    "##### ENG:\n",
    "Import the necessary libraries for the project.\n",
    "TensorFlow is used to build and train the deep learning model.\n",
    "MobileNetV2 is a pre-trained model used for Transfer Learning.\n",
    "ImageDataGenerator is used for preprocessing and augmenting input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configuração do Dataset / Dataset Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PT:*\n",
    "- Define os caminhos para os datasets de treinamento e validação.\n",
    "- Cria geradores de dados que aplicam Data Augmentation nas imagens de treinamento.\n",
    "- O Data Augmentation inclui normalização e transformações para melhorar a generalização do modelo.\n",
    "- As imagens são redimensionadas para 224x224 para compatibilidade com o MobileNetV2.\n",
    "\n",
    "\n",
    "*ENG:*\n",
    "- Define paths for training and validation datasets.\n",
    "- Create data generators that apply Data Augmentation to training images.\n",
    "- Data Augmentation includes normalization and transformations to improve model generalization.\n",
    "- Images are resized to 224x224 to be compatible with MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaique\\AppData\\Local\\Temp\\ipykernel_7200\\2221646573.py:9: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Carregar o modelo pré-treinado sem a última camada\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
    "\n",
    "# Adicionar camadas personalizadas no topo\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)  # Duas classes: Hugh Jackman e Ryan Reynolds\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Congelar camadas base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carregar o modelo pré-treinado / Load the Pre_trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PT:\n",
    "- Carrega o modelo MobileNetV2 pré-treinado na ImageNet sem as camadas de classificação originais.\n",
    "- Adiciona camadas personalizadas para adaptar o modelo ao problema de reconhecimento facial.\n",
    "- O modelo base é congelado para preservar os pesos originais durante o treinamento inicial.\n",
    "\n",
    "ENG:\n",
    "- Load the pre-trained MobileNetV2 model from ImageNet without the original classification layers.\n",
    "- Add custom layers to adapt the model to the face recognition problem.\n",
    "- The base model is frozen to preserve the original weights during the initial training phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 images belonging to 2 classes.\n",
      "Found 61 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Separar validação\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compilar e treinar modelo / Compile and Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PT:\n",
    "- Compila o modelo com o otimizador Adam, uma taxa de aprendizado pequena e a função de perda categorical_crossentropy.\n",
    "- Treina o modelo usando os geradores de treinamento e validação por 10 épocas.\n",
    "\n",
    "ENG:\n",
    "- Compile the model using the Adam optimizer, a small learning rate, and the categorical_crossentropy loss function.\n",
    "- Train the model using the training and validation generators for 10 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaique\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - accuracy: 0.4600 - loss: 2.1313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaique\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.4664 - loss: 2.1402 - val_accuracy: 0.9375 - val_loss: 0.1505\n",
      "Epoch 2/10\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 466ms/step - accuracy: 0.7188 - loss: 0.6207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.7188 - loss: 0.6207 - val_accuracy: 0.8966 - val_loss: 0.1548\n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 772ms/step - accuracy: 0.7649 - loss: 0.7720\n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 151ms/step - accuracy: 0.8438 - loss: 0.4933 - val_accuracy: 0.6562 - val_loss: 0.7265\n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.7982 - loss: 0.4918 - val_accuracy: 0.9310 - val_loss: 0.1692\n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8889 - loss: 0.2536 \n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 892ms/step - accuracy: 0.8332 - loss: 0.3550 - val_accuracy: 0.8750 - val_loss: 0.2811\n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.8750 - loss: 0.2947 - val_accuracy: 0.9310 - val_loss: 0.1642\n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 753ms/step - accuracy: 0.8960 - loss: 0.2277\n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - accuracy: 0.9375 - loss: 0.1735 - val_accuracy: 0.9688 - val_loss: 0.1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Compilar o modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10,  # Ajuste conforme necessário\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save('face_recognition_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Salvando o modelo e Fazendo Reconhecimento / Saving the model and Making Previsions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PT:\n",
    "- Salva o modelo treinado no disco para ser reutilizado no reconhecimento facial.\n",
    "\n",
    "\n",
    "ENG:\n",
    "- Save the trained model to disk for reuse in face recognition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted: Ryan_Reynolds with confidence 0.76\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Carregar o modelo salvo\n",
    "model = load_model('face_recognition_model.h5')\n",
    "\n",
    "# Carregar e processar uma imagem\n",
    "image = cv2.imread('test_Huge_Rey.jpg')\n",
    "image_resized = cv2.resize(image, (224, 224))\n",
    "image_array = np.expand_dims(image_resized, axis=0) / 255.0\n",
    "\n",
    "# Fazer predição\n",
    "predictions = model.predict(image_array)\n",
    "class_indices = train_generator.class_indices\n",
    "classes = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "predicted_class = classes[np.argmax(predictions)]\n",
    "confidence = np.max(predictions)\n",
    "\n",
    "print(f\"Predicted: {predicted_class} with confidence {confidence:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reconhecimento Facial na Imagem / Facial Recognition on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PT:\n",
    "- Carrega o modelo salvo para realizar o reconhecimento facial.\n",
    "- Pré-processa a imagem fornecida para corresponder ao formato de entrada do modelo.\n",
    "- Realiza predições e utiliza coordenadas fornecidas pela face_detection para desenhar retângulos ao redor dos rostos.\n",
    "- Exibe graficamente os resultados indicando o nome da pessoa reconhecida.\n",
    "\n",
    "\n",
    "\n",
    "ENG:\n",
    "- Load the saved model to perform face recognition.\n",
    "- Preprocess the given image to match the model's input format.\n",
    "- Make predictions and use coordinates provided by face_detection to draw rectangles around faces.\n",
    "- Display results graphically, showing the recognized person's name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Carregar o modelo treinado\n",
    "model = load_model('face_recognition_model.h5')\n",
    "\n",
    "# Carregar o classificador de rostos Haar Cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Dicionário de classes\n",
    "class_indices = {'Hugh_Jackman': 0, 'Ryan_Reynolds': 1}\n",
    "classes = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Carregar a imagem\n",
    "image = cv2.imread('test_Huge_Rey.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detectar rostos\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Loop pelos rostos detectados\n",
    "for (x, y, w, h) in faces:\n",
    "    # Recortar o rosto\n",
    "    face = image[y:y+h, x:x+w]\n",
    "    face_resized = cv2.resize(face, (224, 224))\n",
    "    face_array = np.expand_dims(face_resized, axis=0) / 255.0\n",
    "\n",
    "    # Fazer predição\n",
    "    predictions = model.predict(face_array)\n",
    "    predicted_class = classes[np.argmax(predictions)]\n",
    "    confidence = np.max(predictions)\n",
    "\n",
    "    # Adicionar rótulo na imagem\n",
    "    label = f\"{predicted_class} ({confidence*100:.2f}%)\"\n",
    "    color = (0, 255, 0) if predicted_class == 'Hugh_Jackman' else (255, 0, 0)\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(image, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "# Exibir a imagem\n",
    "cv2.imshow('Detected Faces', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
